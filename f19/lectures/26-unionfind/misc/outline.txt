LAST: (minimum) spanning trees
TODAY:
- checking equivalences
- union-find data structure
  . height tracking
  . path compression
THAT'S ALL FOLKS

Important concepts (5 = highest, 1 = lowest)
============================================
[4] review
[5] idea of union-find
[3] equivalence relations
[5] example of basic union-find
[5] complexity of basic union-find
[5] idea of height tracking
[4] example of union-find with height tracking
[4] complexity of union-find with height tracking
[2] proof of complexity bound
[3] idea of path compression
[2] complexity of union-find with path compression

Review
======
- Kruskal's algo for computing minimum spanning trees in weighted graphs
  [leave this pseudocode on some board and update the complexities throughout]
      0. sort edges in increasing weight order          [O(e log e) ]
      1. start with singleton trees                     [O(1)]
      2. for each edge (u,w) of G                       [e * ]
         * are u and w already connected in T?              [O(v)]
           . yes: discard edge                              [O(1)]
           . no: add edge to T                              [O(1)]
         * stop once T has v-1 edges
  . cost O(ev)
- can we do better?


Towards union-find
==================
- we checked "are u and w already connected in T?" using DFS/BFS
  . O(v)
  . this is the best we can do when we know nothing about these vertices
  . but WE put them in T
    . specifically in the various connected components T consists of at each step
    . "are u and w already connected in T?" == "are u and w in the same connected component of T?"
    . we can arrange to know in which connected component they belong
- idea: appoint a CANONICAL REPRESENTATIVE for each connected component
        . think of it as the boss of a clan in old mafia movies
  and arrange that we can easily find the canonical representative of each vertex
        . every gangster has a way to find out who the boss of his clan is
- how does it help us?
  . to check if u and v are already connected in T, FIND their canonical representatives
    . if the same, discard (u,v)
    . if different, add it
      . this turns the two connected components into 1 (their UNION)
      . appoint 1 vertex to be the canonical representative of the union, efficiently

Equivalence relations
=====================
- before we look at the details, consider connectivity algebraically
- "u and v are connected" is a relations between vertices
  . write it as u ## v for short
- what properties does it have?
  . u ## u                            -- reflexivity
  . if u ## v, then v ## u            -- symmetry
  . if u ## v and v ## w, then u ## w -- transitivity
- that's an EQUIVALENCE RELATION
- what is a connected component algebraically?
  . an EQUIVALENCE CLASS
- canonical representative is one element that represents the equivalence class it belongs to
- union-find can be used to determine whether two elements are equivalent
  in any equivalence relation, not just graph connectivity
  . as long as we can pick a canonical representative

Basic union-find
================
- we will explain how union-find works on an example
  . finding a spanning tree for this (unweighted) graph
        0       5
        |\     /|
        | 2---3 |
        |/     \|
        1       4
  . we will consider edges in the order (4,5), (3,5), (1,2), (3,4), (2,3), (0,2), (0,1)
[logistics: divide the board into 4 quadrants
 . top-right:    above graph -- tick edges as they are considered
 . bottom-right: spanning tree as we are constructing it (or use colored chalk on top-right)
 . top-left:     array representation of the union-find DS
 . bottom-left:  graph visualization of the union-find DS]
- we need a data structure to keep track of and find canonical representatives
  . the UNION-FIND DATA STRUCTURE
  . all we need is an array UF such that UF[u] contains the c.rep of u
    (or a way to find it)
- initially, we have singleton trees, so each vertex is its own c.rep
       0 1 2 3 4 5
      [0 1 2 3 4 5]
  . each vertex points to itself
- consider edge (4,5)
  . are 4 and 5 in the same connected component (of the spanning tree)?
    . 4's c.rep is 4
    . 5's c.rep is 5
    . 4 != 5 so they are not connected
    . add it to the spanning tree
    . whom to appoint as the c.rep of the merged connected component?
      . it doesn't matter -- ask if someone's birthday is even or odd
      . say we pick 4
    . UF updated to [write new row, starting from update and then copying the rest]
      [0 1 2 3 4 4]
    . making sense of connected components on array is fine for a computer
      but it quickly gets tricky for us humans
      . visualize the contents of UF as a DIRECTED GRAPH with an edge from u to v if UF[u] = v
        0       5
                |
          2   3 |
                v
        1       4
  . we (re)discovered that trees can be implemented as arrays!
- consider edge (3,5)
  . 3's c.rep is 3; 5's c.rep is 4; 3 != 4 so they are not connected
  . which vertex should we appoint as c.rep?
    . 5? doing so forces us to change UF[4], UF[5] and possibly many more in a larger graph
      . we want to pick one of the old c.reps as the new c.rep
    . 4? that would work [and in fact it will be a better solution]
    . 3? that would work too -- let's do that
    . update UF and graph visualization
          [0 1 2 3 3 4]
- consider edge (1,2)
  . same, pick 1 as c.rep
          [0 1 1 3 3 4]
- consider edge (3,4)
  . 3's c.rep is 3; 4's c.rep is 3; 3 == 3, so discard edge
- consider edge (2,3)
  . usual, pick 3 as c.rep
          [0 3 1 3 3 4]
  . graph visualization of UF extended with an edge that is NOT in original graph!
    . they are different graphs and that convey different information
- consider edge (0,2)
  . pick 0 as c.rep
          [0 1 1 0 3 4]
- no need to consider (0,1): we already have 5 edges (= v-1)
- what is the complexity of answering the question "is u connected to w"?
  . find the c.rep of u: O(v) -- may have to go through most vertices
  . find the c.rep of w: O(v)
  . check if they are equal: O(1)
  . so, it's O(v)
- update complexity in Krusal's pseudocode
  . if we swap union-find for BFS/DFS, cost remains O(ev)
  . no savings
- can we do better?

Height tracking
===============
- observe that the graph visualization of the UF data structure is a tree
  . the canonical representative is the root
  . edges point towards the root
  . as we build it, we have a forest with each tree having this property
  . we repeatedly merge the roots of 2 trees
  . the cost is the height of the tree
- we know that the height of a balanced binary tree is logarithmic
  . can we arrange so that our UF tree is balanced?
- we can at least minimize the height of the UF tree
  by always merging shorter trees into taller trees
  . height of the merged tree is still the height of the taller tree
  . height increases only when merging trees of the same height
- to do so, we need to track the height of our trees
  . how? [audience participation]
    . use a struct with height and c.rep
    . can we do better?
  . observations:
    . we need the height only when we reach the root (= canonical representative)
    . for a c.rep, UF points to itself
  . we can use the same number to indicate the height in a c.rep and a parent vertex otherwise
    . but then how to tell if 1 is a height or a parent?
    . all we need is a flag, a single bit
    . use the sign bit of the values in UF for that purpose
      . negative numbers represent heights
        . only associated with c.reps
      . positive numbers represent parent in tree
        . associated with vertices that are not c.reps
- let's try that on the (weighted) road map graph from last lecture
  [logistics:
   - use slides from last time -- sequence remains the same
   - develop UF array on one side of the board
   - develop graph visualization on the other side
   - start making updates on array first and then on graph visualization
   - use colored chalk for changes on array: changes first, what doesn't change after]
  . the minimum spanning tree we will obtain will be the same
    . only change is how we answer the questions "are these vertices already connected?"
  . example development of the UF array
      vertices as letter     A  B  C  D  E  F  G  H  I  J
      vertices as numbers    0  1  2  3  4  5  6  7  8  9      (choices)
                  (start)  [-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 ]
                add (H,G)  [-1 -1 -1 -1 -1 -1 -2  6 -1 -1 ]    (*)
                add (C,E)  [-1 -1  4 -1 -2 -1 -2  6 -1 -1 ]    (*)
                add (I,C)  [-1 -1  4 -1 -2 -1 -2  6  4 -1 ]
                add (D,E)  [-1 -1  4  4 -2 -1 -2  6  4 -1 ]
          don't add (D,C)
          don't add (D,I)
                add (F,H)  [-1 -1  4  4 -2  6 -2  6  4 -1 ]
                add (B,E)  [-1  4  4  4 -2  6 -2  6  4 -1 ]
                add (A,I)  [ 4  4  4  4 -2  6 -2  6  4 -1 ]
                add (F,J)  [ 4  4  4  4 -2  6 -2  6  4  6 ]
          don't add (A,C)
          don't add (B,C)
          don't add (H,J)
                add (A,H)  [ 4  4  4  4  6  6 -3  6  4  6 ]    (*)
          DONE -- we have all the edges we need
- what is the cost of checking if two vertices are connected using height tracking?
  . i.e., of finding a c.rep?
  . i.e., what is the height of a tree?
- best case: O(1) -- every vertex is connected to its c.rep directly
- worst case? intuitively, it's when we have a balanced binary tree
  . because we always merge the shorter tree into the taller tree
  . we increase the height only when two trees have the same height
- let's turn this into a property
      A tree of height h has at least 2^(h-1) vertices
- proof: by induction on h
  base case: h = 0, so we have a single vertex and 2^(1-1) = 2^0 = 1

  inductive case: this tree was obtained by merging two trees T1 and T2 of height h1 and h2
    3 subcases:
    . h1 > h2: then we merge T2 into T1 to obtain T
      . height of T is h1
      . T has at least 2^(h1-1) + 2^(h2-2) vertices which is more than 2^(h1-1)
    . h1 < h2: dual
    . h1 = h2: we can merge either T1 into T2 or T2 into T1 to obtain T
      . height of T is h1 + 1
      . T has at least 2^(h1-1) + 2^(h1-1) = 2^h1 = 2^((h1+1)-1) vertices
- how does this help us?
  . a tree of height h has AT LEAST 2^(h-1) vertices, so
  . a tree with v vertices has height AT MOST log v + 1
  . so the height of a UF tree is O(log v)
- update complexity in Krusal's pseudocode
  . cost of using union-find with height tracking is O(e log e + e log v)
    . e in O(v^2) so log e in O(log v^2) = O(2 log v) = O(log v)
    . so cost is O(e log v) -- often equal to the cost of sorting the edges O(e log e)
  . no improvement but remember that union-find is used for any equivalence relation

Path compression
================
- can we do even better?
- when we find the c.rep v_0 of a vertex v_n, update UF to reflect that: UF[v_n] = v_0
  . do the same for all vertices v_i between v_n and v_0: UF[v_i] = v_0
  . next time we ask for the c.rep of one of them, it is returned in constant time
- this is PATH COMPRESSION
- what does it do the complexity of finding a c.rep?
  . have you heard of the Ackermann function?
    . it grows very very fast
       Ack(0,0) = 1
       Ack(1,1) = 3
       Ack(2,2) = 7
       Ack(3,3) = 61
       Ack(4,4) > number of atoms in the universe
    . if your curious, it is defined as
       Ack(0, n) = n+1
       Ack(m, 0) = Ack(m-1, 1)              if m > 0
       Ack(m, n) = Ack(m-1, Ack(m, n-1))    if m, n > 0
  . cost of finding a c.rep is O(1 + A^-1(v)) amortized
    . where A(n) = Ack(n,n) -- the inverse of that
    . that's almost constant!
    . cost of checking equivalence of any two elements in an equivalence relation


[end of the course]
[make some closing remarks if desired]
