LAST: C memory operations, undefined behaviors
TODAY:
- numbers in C
- implementation-defined behavior
- other C types
NEXT: putting C to good use

Important concepts (5 = highest, 1 = lowest)
============================================
[5] implementation-defined behaviors
[4] long/short/char + unsigned versions as numbers
[4] stdint numbers
[4] casting among numbers
[2] floating point numbers
[2] enum and union types
[3] switch statements


Implementation-defined behaviors
=================================
- last lecture: new and different (and sometimes bad) ways C handles memory
- this lecture: let's see what kind of trouble numbers can get us into
- in C0/C1, the size of int's was fixed to 32 bits, size of pointers to 64 bits
- in C, the size of int's and pointers has evolved over time

  pointer size     8             16               32                 64
      int size     8             16               32                 32
                -------------------------------------------------------->
                  '70s          '80s             '90s                now
                              Apple II            PC's
                            Commodore 64
- a bit of history
  . early computers had 8-bit addresses
    . 256 bytes of addressable memory!
    . RAM was very expensive
    . yet fancy compared to computer that sent Apollo 11 to the moon (displayed at Cape Canaveral)
  . early '80s: memory measured in kilobytes
    . Commodore 64 had 64K of RAM
  . '90s: memory measured in megabytes
    . with 32 bit addresses, 4GB RAM (reached routinely only recently)
  . today: memory measured in gigabytes
    . nobody has 2^64 bytes of RAM
- the C standard says that it is for the compiler to define the size of an int
  (within some constraints)
  . it is not undefined behavior, but IMPLEMENTATION-DEFINED
  . the programmer can find out how big an int is in <limits.h>
    . INT_MIN and INT_MAX are defined there
  . most programmers don't need to know
    . just write int in their code and compiler will use whatever internal size
    . as long as the number of bits in an int is not critical (but not OK to encode pixels)
- same thing for pointers
  . code written in the '70s still works on today's hardware
  . as long as programmer used sizeof in malloc
- int's have undefined behaviors of their own
  . expected (safety violations in C0)
    . division/modulus by 0, or INT_MIN divided/mod'ed by -1
    . shift by more than size of int (32 bits nowadays)
  . unexpected (C0 does something reasonable while C doesn't)
    . overflow is UNDEFINED BEHAVIOR in C
      . C program does not necessarily use 2's complement!
      . makes it really hard to reason about C programs that use arithmetic
        . optimizing compiler cannot simplify x+x-x to x
      . gcc provides -fwrapv flag to force the use of 2's complement for int's
        [log into some Linux machine and run
         # man gcc
         to show the hundreds of flags that gcc supports
         (on Mac, only the main flags are shown -- not as dramatic)]

Other integer types in C
=========================
- C0 has a single type of numbers: int
- C has many more
  . an 8-bit int (even 16) was too small for many practical applications even in the '70s
    . accountant needed to deal with expenses of more than $127! (even accounting for inflation)
  . long: more bits than int
    . nowadays implementation-defined to 64 bits (8 bytes)
- back in the day, memory was scarce so why waste a whole int to count up to 1000?
  . short: fewer bits than int (typically)
    . nowadays 16 bits (2 bytes)
- even that is too much to count up to 100
  . char: 1 byte (8 bits ... or more ... but not really nowadays)
  . A CHAR IS A NUMBER
    . displayed as a character by printf when using %c
    . 'a' is just convenience syntax
- and lots of code doesn't use negative numbers
  . unsigned long/int/short/char: same number of bits but to represent only non-negative numbers
    . twice as many numbers
  . unsigned numbers do follow the laws of modular arithmetic
    . overflow is defined to wrap around
  . whether char (by itself) is signed or unsigned is implementation-defined
  . size_t is the size of a pointer
    . nowadays 64 bits (8 bytes)
    . argument of malloc/calloc, array indices, etc
- summary
    signed           unsigned            today      C99 constraints
    -----------------------------------------------------------------------
    signed char      unsigned char       8 bits     exactly 1 byte
    short            unsigned short     16 bits     at least (-2^15, 2^15)
    int              unsigned int       32 bits     at least (-2^15, 2^15)
    long             unsigned long      64 bits     at least (-2^31, 2^31)
  (and there are a few more)

Fixed-size numbers
==================
- what if we need to use a specific number of bits?
  . bit patterns (e.g., pixels)
  . compilers/interpreters
- <stdint.h> defines a number of types that have a fixed size
  . both signed and unsigned versions

    fixed-size      today's         today's        fixed-sized
      signed     signed equiv.   unsigned equiv.     unsigned
    -----------------------------------------------------------
     int8_t        signed char   unsigned char       uint8_t
    int16_t        short         unsigned short     uint16_t
    int32_t        int           unsigned int       uint32_t
    int64_t        long          unsigned long      uint64_t

- this is what you want to use if you know a value will have exactly N bits

Integer casting
===============
- we go back and forth between different number types with CASTS
      int x = 3;
      long y = (long)x;
  . literal numbers (e.g., 3) always have type int
- C introduces implicit casts whenever it sees fit
      long x = 3;
  is implicitly
      long x = (long)3;
  . implicit casts are dangerous:
      long x = 1 << 40;
    is undefined
     . 1 is viewed as a (32-bit) int
     . 1 << 40 shifts 1 (32 bits) by 40
     . the result (if the program doesn't crash) is converted to a long
     . and assigned to x
- CASTING RULES
  . when casting signed to/from unsigned numbers of the same size, BIT PATTERN IS PRESERVED
    . signed char x = 3;                   // x is   3 (= 0x03)
      unsigned char y = (unsigned char)x;  // y is   3 (= 0x03)
    . signed char x = -3;                  // x is  -3 (= 0xFD)
      unsigned char y = (unsigned char)x;  // y is 253 (= 0xFD)
    . this is actually implementation defined (but commonplace)
  . when casting small to big number of same signedness, VALUE IS PRESERVED
     . signed char x = 3;                  // x is   3 (= 0x03)
       int y = (int)x;                     // y is   3 (= 0x00000003)
     . signed char x = -3;                 // x is  -3 (= 0xFD)
       int y = (int)x;                     // y is  -3 (= 0xFFFFFFFD)
     . uses SIGN EXTENSION
  . when casting big to small number of the same signedness, makes sure value will fit
    . otherwise undefined behavior
- casting across signedness AND size
  . compiler may apply casting rules in either order
    . unsigned char x = 0xFD;             // x is 253
      int y = (int)x;                     // y is ???
                              (unsigned char)
                                    0xFD = 253
                                   /    \
           cast to (unsigned int) /      \ cast to (signed char)
                  preserve value /        \ preserve bit pattern
                                /          \
                    253 = 0x000000FD      0xFD = -3
                               |            |
          cast to (signed int) |            | cast to (signed int)
          preserve bit pattern |            | preserve value
                               |            |
                    253 = 0x000000FD      0xFFFFFFFD = -3

  . in reality, order of cast is defined in C99 !
    . but who remembers it!?
  . when you need to cast across signedness and size, BE EXPLICIT
    . unsigned char x = 0xFD;             // x is 253
      int y1 = (int)(unsigned int)x;      // y1 is 253
      int y2 = (int)(signed char)x;       // y2 is -3

Floating point numbers
======================
- type float supports floating point numbers (nowadays 32 bits)
  . float x = 0.1
    float y = 2.0235E-27
- very large range, comes at the cost of precision
  . rounding errors manifest in operations
    . #include <math.h>
      #define PI 3.14159265
      sin(PI) != 0.0
    . (10E20 / 10E10) * 10E10 != 10E20  // depends on compiler
    . for (float res = 0.0; res != 5.0; res += 0.1) {
        printf("res = %f\n", res);
      }   // infinite loop!
      Why??
      . 0.1 is periodic in base 2: 0.0[0011]*
        . repeatedly multiply by 2 and harvest the digit to the left of decimal point
- this is why float is not in C0
  . makes it impossible to reason about programs
- type double for double precision floating point numbers (nowadays 64 bits)
  . similar problems

Union and enum types
====================
- problem: define binary tree with int data in leaves only
  [if they did ropes this semester, this is very similar]
  . could be
    . empty (say we don't want to use NULL for it)
    . leaf with int data
    . inner node with pointers to 2 children
  . struct with all needed fields and nodetype to say which kind we have
      typedef struct ltree leafytree;
      struct ltree {
        int nodetype;
        int data;
        leafytree *left;
        leafytree *right;
      };
  . wasteful!
    . 3 possible nodetype values but uses a whole int
    . inner nodes do not need data
    . leaves do not not need left and right
    . empty tree does not need any
- use ENUM TYPE to let the compiler deal with nodetype
      enum nodetype { INNER, LEAF, EMPTY };
  . provides 3 symbolic values (INNER, LEAF, EMPTY) to use as node types
  . compiler can optimize space use as it sees fit
- use UNION TYPE to have same space used either for inner node or for leaf
  . create a struct for just left and right pointers of inner nodes
      struct innernode {          // inner node: left and right subtrees
        leafytree *left;
        leafytree *right;
      };
  . union is either leaf data or inner node pointers
      union nodecontent {         // contents of a non-empty node:
        int data;                 // EITHER an int
        struct innernode node;    //     OR and inner node
      };
  . struct ltree combines type and content (it could have other fields)
      struct ltree {
        enum nodetype type;
        union nodecontent content;
      };
  . creating tree with
    . an inner node,
        leafytree *T = malloc(sizeof(leafytree));
        T->type = INNER;
    . an empty left subtree,
        T->content.node.left = malloc(sizeof(leafytree));
        T->content.node.left->type = EMPTY;
    . and a leaf containing 42 as its right subtree
        T->content.node.right = malloc(sizeof(leafytree));
        T->content.node.right->type = LEAF;
        T->content.node.right->content.data = 42;
  . C11 standard allows more compact declarations (anonymous enum/union)


Switch statements
=================
- generalized conditional that discriminates on possible values of an expression
  . adding all the values in a leafytree
      int add_tree(leafytree *T) {
        ASSERT(is_tree(T));
        int n = 0;

        switch (T->type) {
        case INNER:
          n += add_tree(T->content.node.left);
          n += add_tree(T->content.node.right);
          break;

        case LEAF:
          n = T->content.data;
          break;

        default:
          n = 0;
        }

        return n;
      }
  . one case for each value of interest
  . terminate case with break or execution will continue on to next case
  . default for all remaining values
