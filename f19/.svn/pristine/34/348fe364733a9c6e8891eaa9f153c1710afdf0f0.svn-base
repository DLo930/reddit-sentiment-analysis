LAST: correctness of array code
TODAY:
- big-O
- order (linear search on sorted arrays)
- sorting (selection sort)
NEXT: binary search

Important concepts (5 = highest, 1 = lowest)
============================================
[5] cost
[3] timing
[5] step count
[4] definition of big-O
[5] common complexity classes
[5] cost of linear search
[3] cost of linear search on sorted arrays
[5] idea of selection sort, examples, visual invariants
[4] arrayutil library
[2] find_min implementation (just interface)
[5] code for selection sort (deliberate programming)
[5] safety and correctness of selection sort code (reasoning about pictures)
[5] cost of selection sort

Review
======
- safety and correctness of array code
- linear search through an array

Cost
====
- how long does code for search take to run?
- what do we mean by "how long"?
  . clock time?
      # cc0 search.c0 search-time.c0
      # time ./a.out -n 1000000 -r 200
    (repeat a couple of time)
    note: number changes slightly, worse on different computers
    gives us information though, e.g., doubles with -n 2000000
- criteria for answering question
  . general:
     . applicable to a large class of programs, algorithms and even problems
     . independent of particular hardware
     . applicable to many types of resources (time, space, energy, etc)
  . mathematically rigorous
  . useful:
    . not predict actual run time
    . but help us select among various algorithms for a problem
      . e.g., POW vs. mystery function
- how long = number of steps

Naive step count
================
- how many operations does search do to search an n-element array?
  (contracts off)
  . 1 + 3n + 1
    i=0
    loop: n times
      i < n
      if (A[i] == x)
      i++
    return -1
- always?
  . fewer if x is found early
  . this is the WORST CASE scenario
- worst case analysis is typical (but we'll talk of others too)
- does not depend on A nor x
  . n is the MEASURE OF INPUT
  . T(n) = 3n + 2
- what about retrieving arguments?  How many steps in i++?
  . giving specific numbers is hard (especially for more complex code)
    at most some fixed number a of steps outside loop
    at most some fixed number b of steps inside loop
    T(n) = an + b

Towards big-O [do mainly based on pictures]
=============
- cost functions: f: N -> N  (for us)
- define cost so that it is easy to answer the question
    "is f better than g"
- naive definition 1:
    f is better than g if
      for all n \in N. f(n) <= g(n)
  . problem: g may be better at first and then f is always better
  . for small inputs, which algorithm to use doesn't matter
- naive definition 2:
    f is better than g if
      there is n0 \in N s.t.
      for all n >= n0. f(n) <= g(n)
  . problem: depends on exact choice of constants, but they are hard to know
- final definition
    f is better than g if
      there is n0 \in N and real c > 0 s.t.
      for all n >= n0. f(n) <= c g(n)
  . rather than "f is better than g", we say f \in O(g)
  . common way to compare programs/algos/problems
  . not just running time, but also space, energy, etc
- O(g(n)) is a SET:
  {f(n) s.t. there is n0 in N and real c>0 s.t. for all n >= n0. f(n) <= c g(N)}

Big-O practice
==============
- show that 3n + 2 in O(3n + 2)   [c=1 & n0=0]
- show that 3n + 2 in O(n)        [c=4 & n0=1 for example]
  . O(n) is simpler however
  . O(n) = O(3n + 2)
  . always go for the SIMPLEST bound
- show that 3n + 2 in O(n^2)      [c=1 & n0=4, or c=2 & n0=2, etc.]
  . O(n) is more precises however
  . O(n) \subseteq O(n^2)
  . always go for the TIGHTEST bound
- show that n^2 \not\in O(n)      [n^2 grows faster than cn for any c]
  . hierarchy of complexity classes
- canonical complexity classes used in this course (both to describe and classify algos)
  . O(1)       -- constant
  . O(log n)   -- logarithmic
  . O(n)       -- linear
  . O(n log n) -- ??
  . O(n^2)     -- quadratic
  . O(2^n)     -- exponential
- there is nothing special about n
  . the size of the input can be called anything
  . sometimes multiple quantities.  E.g., w * h pixel image
    . inverting every pixel?  O(wh)
    . drawing a border?  O(w + h)
- to visualize, use https://www.desmos.com/calculator

Back to linear search
=====================
- complexity?  O(n)
- can we do better if array cooperates?
  . if array is sorted, return -1 as soon as we encounter an element > x
  . complexity?  Still O(n): x could be larger than anything in array
  . (we will see a different approach next time)

Sorted arrays
=============
- updated code
    int search(int x, int[] A, int n)
    //@requires n == \length(A);
    //@requires is_sorted(A, 0, n); // ADDED
    /*@ensures (\result == -1 && !is_in(x, A, 0, n))
            || (0 <= \result && \result < n && A[\result] == x)
    @*/
    {
      for (int i = 0; i < n; i++)
      //@loop_invariant 0 <= i && i <= n;
      //@loop_invariant !is_in(x, A, 0, i);
      {
        if (A[i] == x) return i;
        if (x < A[i]) return -1;    // ADDED
        //@assert (A[i] < x);       // ADDED
      }
      return -1;
    }
- how do we prove correctness? [do only if time]
  . return i still works
  . is_in is not sufficient for the added 'return -1'
  . draw picture:
          0               i            n
         ------------------------------
      A: |               |            |
         ------------------------------
          x > A[0,i)
    . in generic iteration, x > A[0, i)
      NEW NOTATION: x > A[lo,hi) -- true if lo=hi
    . updated loop invariant with steps of proofs as //@asserts (very detailed):
    int search(int x, int[] A, int n)
    //@requires n == \length(A);
    //@requires is_sorted(A, 0, n);
    /*@ensures (\result == -1 && !is_in(x, A, 0, n))
            || (0 <= \result && \result < n && A[\result] == x)
    @*/
    {
      for (int i = 0; i < n; i++)
      //@loop_invariant 0 <= i && i <= n;
      //@loop_invariant gt_seg(x, A, 0, i);     // implies !is_in(x, A,0,i)  // ADDED
      //@loop_invariant !is_in(x, A,0,i);
      //@loop_invariant le_segs(A,0,i, A,i,n);  // because is_sorted(A,0,n)  // ADDED
      {
        if (A[i] == x) return i;
        if (x < A[i]) {
          //@assert lt_seg(x, A,i,n);           // implies !is_in(x, A,i,n)
          //@assert !is_in(x, A,i,n);
          return -1;
        }
        //@assert A[i] < x;                     // implies gt_seg(A,0,i+1)
        //@assert gt_seg(A,0,i+1);
      }
      return -1;
    }
- final return:
  i == n, therefore A[0,n) < x
  A[0,n) < x entails x not in A[0,n)
- early return:
  A[0,i) < x entails x not in A[0,i)
  x < A[i] and 0 <= i < n and sorted(A, i, n) entail x not in A[i,n)
  so x not in A[0,n)

Sorting
=======
- we examine simple algorithm, SELECTION SORT, others next week
  real reason: practice deliberate programming
  . example: A = [9, 13, 18, 3, 12, 5, 7, 6]
  . what goes in A[0]?
    . smallest element in A[0, n)
  . swap with current A[0]
  . what goes in A[1]?
    . smallest element in A[1, n)
  . swap with current A[1]
  . repeat till all elements are in right place
- let's have a function find_min that returns of index of smallest element in a range [lo, hi)
  . contracts:
    int find_min(int[] A, int lo, int hi)
    //@requires 0 <= lo && lo < hi && hi <= \length(A);
    //@ensures lo <= \result && \result < hi
            && le_seg(A[\result], A, lo, hi);
  . implementation: similar to linear search, left as exercise
- what do we know at iteration i?
          0                i                    n
         ---------------------------------------
      A: |                |                    |
         ---------------------------------------
           A[0,i) sorted     A[0,i) <= A[i,n)
  . 0 <= i <= n
  . A[0, i) sorted
  . A[0, i) <= A[i, n)
- these are our loop invariants!
- here's our code (generalized to sort between lo and hi)
     void sort(int[] A, int lo, int hi)
     //@requires 0 <= lo && lo <= hi && hi <= \length(A);
     //@ensures is_sorted(A, lo, hi);
     {
       for (int i = lo; i < hi; i++)
       //@loop_invariant lo <= i && i <= hi;
       //@loop_invariant is_sorted(A, lo, i);
       //@loop_invariant le_segs(A, lo, i, A, i, hi);
       {
         int m = find_min(A, i, hi);
         swap(A, i, m);
       }
    }
         0      lo                i                     hi    \length(A)
         -----------------------------------------------------
      A: |     |                 |                     |     |
         -----------------------------------------------------
                 A[lo,i) sorted    A[lo,i) <= A[i,hi)
  . return type is void
    . sort doesn't return anything
    . it sorts array IN-PLACE
- is it correct?
  . INIT: trivial
  . PRES:
    . lo <= i && i <= hi (done as usual)
    . is_sorted(A, lo, i)
      i' = i+1
      since A[lo, i) <= A[i, hi) -- LI3
      A[lo, i+1) is sorted no matter what element of A[i,hi) we put in A[i]
    . A[lo, i) <= A[i, hi)
      At the end, A[i] <= A[i,hi) -- by postcondition of find_min
      in particular A[i] < A[i+1, hi)
      A[lo,i+1) is A[lo,i) plus A[i]
    . EXIT:
      . i == hi (usual argument)
      . is_sorted(A, lo, hi)
      . note: LI3 used only to prove PRES, not EXIT
    . TERM: i increases at each iteration and can't exceed hi

Cost of selection sort
======================
- measure of input? length of array segment: n = hi - lo
- cost of find_min?  O(n)  --- n-i in i-th iteration of loop
- cost of sort?  n + (n-1) + ... + 2 + 1 = n(n+1)/2
- worst case complexity of selection sort?  O(n^2)
- best case complexity?  same!
